{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw_les_7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp852UmdGz9-"
      },
      "source": [
        "1. Сделайте краткий обзор любой статьи посвященной тому или иному алгоритму для object detection, который не рассматривался на уроке. Проведите анализ: Чем отличается выбранная вами на рассмотрение архитектура нейронной сети от других архитектур? В чем плюсы и минусы данной архитектуры? Какие могут возникнуть трудности при применении данной архитектуры на практике?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfU0fmlzG7P4"
      },
      "source": [
        "[Xception: компактная глубокая нейронная сеть](https://habr.com/ru/post/347564/)\n",
        "\n",
        "[Going Deeper with Convolutions](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)\n",
        "\n",
        "В 2016 году Франсуа Шолле (François Chollet), автор и разработчик фреймворка Keras, опубликовал статью, в которой предложил использовать так называемый экстремальный Inception-модуль, также известный как depthwise separable convolution.\n",
        "\n",
        "**Depthwise separable convolution**\n",
        "\n",
        "Когда речь идёт о depthwise separable convolution, подразумевается, что сначала делают свёртку по каналам, а потом 1х1 свёртку\n",
        "\n",
        "\n",
        "**Почему это делает сеть компактнее?**\n",
        "\n",
        "Давайте разберём конкретный пример. Пусть мы сворачиваем изображение с 16 каналами свёрточным слоем с 32 фильтрами. Суммарно этот свёрточный слой будет иметь $16*32*3*3=4608$ весов, так как у нас будет $16*32$ свёрток 3х3.\n",
        "\n",
        "Сколько же весов будет в аналогичном depthwise separable convolution блоке? Во-первых, у нас будет $16*32*1*1=512$ весов у pointwise convolution. Во-вторых, у нас будет $32*3*3=288$ весов у depthwise convolution. В сумме получим 800 весов, что намного меньше, чем у обычного свёрточного слоя.\n",
        "\n",
        "**Почему это вообще работает?**\n",
        "\n",
        "Обычный свёрточный слой одновременно обрабатывает как пространственную информацию (корреляцию соседних точек внутри одного канала), так и межканальную информацию, так как свёртка применяется ко всем каналам сразу. Архитектура Xception базируется на предположении о том, что эти два вида информации можно обрабатывать последовательно без потери качества работы сети, и раскладывает обычную свёртку на pointwise convolution (которая обрабатывает только межканальную корреляцию) и spatial convolution (которая обрабатывает только пространственную корреляцию в рамках отдельного канала).\n",
        "\n",
        "**Сравнение с другими архитектурами**\n",
        "Xception превосходит по точности ResNet50 и лишь чуть-чуть уступает InceptionResNetV2, при этом существенно выигрывая по размерам, а значит по требуемым ресурсам как для обучения, так и для использования этой модели.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60ty4yKAgOL4"
      },
      "source": [
        "2. Запустите детектор (ssdMobile_v2 или faster_rcnn, или любой другой детектор) для своей картинки и попробуйте найти 10 объектов, 100 объектов.\n",
        "\n",
        "3. (не обязательное) Ссылка на репозиторий с полным кодом для обучения ssd нейросети - https://github.com/sergeyveneckiy/ssd-tensorflow. Попробуйте улучшить точность ее работы и напишите отчет, что вы пробовали изменить в ее параметрах и как это отражалось на процессе обучения нейронной сети. Обратите внимание! Мин. сист. требования для запуска данного проекта - это минимум 8 Gb ОЗУ. Если у вас недостаточно мощности компьютера, то вы можете просто изучить содержимое исходного кода и датасета данного проекта.</li>"
      ]
    }
  ]
}